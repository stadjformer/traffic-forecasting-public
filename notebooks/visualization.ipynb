{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Forecasting Visualizations\n",
    "\n",
    "Creates visualizations comparing ground truth (geographic graph) vs learned graph:\n",
    "1. Node degree comparison\n",
    "2. Graph adjacency for selected nodes (animated)\n",
    "3. 6-hour rush hour traffic predictions (animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "if not load_dotenv(\".env_jupyter\"):\n",
    "    raise RuntimeError(\"specified .env file not found\")\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from utils.inference import get_learned_adjacency_matrix, get_model_predictions_cached\n",
    "from utils.visual import (\n",
    "    animate_traffic_heatmap,\n",
    "    create_geographic_nodes_animation,\n",
    "    create_node_degree_comparison,\n",
    "    select_geographically_dispersed_nodes,\n",
    ")\n",
    "\n",
    "# Enable autoreload to automatically reload modules when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASETS = [\"METR-LA\", \"PEMS-BAY\"]  # Process both datasets\n",
    "MODEL_PREFIX = \"STGFORMER_FINAL\"  # Final model (short, 20 epochs)\n",
    "EXPERIMENT_NAME = \"final_k16\"  # Short name for saved artifacts\n",
    "OUTPUT_DIR = Path(\"../docs/img\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Animation settings\n",
    "ANIMATION_FPS = (\n",
    "    1  # Frames per second (e.g., 0.5 = 2 seconds per frame, 1.0 = 1 second per frame)\n",
    ")\n",
    "\n",
    "# CVD-friendly mode (Color Vision Deficiency)\n",
    "CVD_FRIENDLY = (\n",
    "    True  # Set to True to use CVD-safe colormaps (viridis instead of plasma/RdYlGn)\n",
    ")\n",
    "\n",
    "# Basemap settings\n",
    "BASEMAP_SOURCE = \"CartoDB.Positron\"  # Options: \"CartoDB.Voyager\", \"CartoDB.Positron\", \"OpenStreetMap.Mapnik\"\n",
    "\n",
    "print(f\"Model: {MODEL_PREFIX}\")\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Datasets: {', '.join(DATASETS)}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Animation FPS: {ANIMATION_FPS}\")\n",
    "print(f\"CVD-friendly: {CVD_FRIENDLY}\")\n",
    "print(f\"Basemap: {BASEMAP_SOURCE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Visualizations for Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DATASET_NAME in DATASETS:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Processing {DATASET_NAME}\")\n",
    "    print(f\"{'=' * 60}\\n\")\n",
    "\n",
    "    # Load graph metadata\n",
    "    adj_mx_gt, _, locations = utils.io.get_graph_metadata(DATASET_NAME)\n",
    "    num_sensors = len(locations)\n",
    "    print(f\"Number of sensors: {num_sensors}\")\n",
    "\n",
    "    # Find the 7am index FIRST so we only compute predictions for that window\n",
    "    print(\"\\nFinding 7am rush hour window...\")\n",
    "    dataset_hf = utils.io.get_dataset_hf(DATASET_NAME)\n",
    "    test_df = dataset_hf[\"test\"].to_pandas()\n",
    "\n",
    "    # Get timestamps from node 0\n",
    "    node_ids = sorted(test_df[\"node_id\"].unique())\n",
    "    timestamps_df = test_df[test_df[\"node_id\"] == node_ids[0]]\n",
    "    test_timestamps = timestamps_df[\"t0_timestamp\"].values\n",
    "\n",
    "    test_ts_parsed = [datetime.fromisoformat(ts) for ts in test_timestamps]\n",
    "    morning_7am_indices = [\n",
    "        idx for idx, ts in enumerate(test_ts_parsed) if ts.hour == 7 and ts.minute == 0\n",
    "    ]\n",
    "\n",
    "    if len(morning_7am_indices) > 0:\n",
    "        start_idx = morning_7am_indices[0]\n",
    "    else:\n",
    "        morning_indices = [\n",
    "            idx for idx, ts in enumerate(test_ts_parsed) if 6 <= ts.hour <= 8\n",
    "        ]\n",
    "        start_idx = morning_indices[0] if morning_indices else 0\n",
    "\n",
    "    # Extract 6 hours of continuous data (72 timesteps = 6 samples)\n",
    "    num_samples_for_6h = 72 // 12\n",
    "    end_idx = start_idx + num_samples_for_6h\n",
    "\n",
    "    print(f\"  Will use samples {start_idx} to {end_idx} (6 samples for 6-hour window)\")\n",
    "\n",
    "    # Load model predictions ONLY for the needed window\n",
    "    predictions, ground_truth = get_model_predictions_cached(\n",
    "        dataset_name=DATASET_NAME,\n",
    "        hf_repo_prefix=MODEL_PREFIX,\n",
    "        sample_indices=(start_idx, end_idx),  # Only compute what we need!\n",
    "    )\n",
    "    print(f\"Predictions shape: {predictions.shape}\")\n",
    "\n",
    "    # Load learned adjacency matrix\n",
    "    adj_mx_model = get_learned_adjacency_matrix(\n",
    "        dataset_name=DATASET_NAME,\n",
    "        hf_repo_prefix=MODEL_PREFIX,\n",
    "    )\n",
    "    print(f\"Learned adjacency shape: {adj_mx_model.shape}\")\n",
    "\n",
    "    # Compute node degrees for node selection\n",
    "    degree_gt = np.abs(adj_mx_gt).sum(axis=1)\n",
    "\n",
    "    # Select geographically dispersed nodes\n",
    "    selected_nodes = select_geographically_dispersed_nodes(locations, degree_gt)\n",
    "    print(f\"Selected {len(selected_nodes)} geographically dispersed nodes\")\n",
    "\n",
    "    # 1. Node Degree Comparison\n",
    "    print(\"\\n1. Creating node degree comparison...\")\n",
    "    output_path = (\n",
    "        OUTPUT_DIR\n",
    "        / f\"{EXPERIMENT_NAME}_{DATASET_NAME.lower()}_node_degree_comparison.png\"\n",
    "    )\n",
    "    create_node_degree_comparison(\n",
    "        adj_mx_ground_truth=adj_mx_gt,\n",
    "        adj_mx_model=adj_mx_model,\n",
    "        locations=locations,\n",
    "        output_path=output_path,\n",
    "        dataset_name=DATASET_NAME,\n",
    "        cvd_friendly=CVD_FRIENDLY,\n",
    "        basemap_source=BASEMAP_SOURCE,\n",
    "    )\n",
    "\n",
    "    # Display the image\n",
    "    from IPython.display import Image, display\n",
    "\n",
    "    display(Image(filename=str(output_path)))\n",
    "\n",
    "    # 2. Geographic Nodes Animation\n",
    "    print(\"\\n2. Creating geographic nodes animation...\")\n",
    "    output_path = (\n",
    "        OUTPUT_DIR\n",
    "        / f\"{EXPERIMENT_NAME}_{DATASET_NAME.lower()}_geographic_nodes_comparison.gif\"\n",
    "    )\n",
    "    frame_duration = 1.0 / ANIMATION_FPS  # Convert FPS to seconds per frame\n",
    "    create_geographic_nodes_animation(\n",
    "        adj_mx_ground_truth=adj_mx_gt,\n",
    "        adj_mx_model=adj_mx_model,\n",
    "        locations=locations,\n",
    "        output_path=output_path,\n",
    "        selected_nodes=selected_nodes,\n",
    "        frame_seconds=frame_duration,\n",
    "        cvd_friendly=CVD_FRIENDLY,\n",
    "        basemap_source=BASEMAP_SOURCE,\n",
    "    )\n",
    "\n",
    "    # Display the GIF\n",
    "    display(Image(filename=str(output_path)))\n",
    "\n",
    "    # 3. Rush Hour Traffic Animation\n",
    "    print(\"\\n3. Creating rush hour traffic animation...\")\n",
    "\n",
    "    # Reshape to continuous timesteps (predictions and ground_truth already have only the 6 samples)\n",
    "    gt_6h = ground_truth.reshape(-1, num_sensors, ground_truth.shape[-1])\n",
    "    pred_6h = predictions.reshape(-1, num_sensors, predictions.shape[-1])\n",
    "\n",
    "    # Generate time labels\n",
    "    start_time = test_ts_parsed[start_idx]\n",
    "    date_str = start_time.strftime(\"%Y-%m-%d\")\n",
    "    time_labels_6h = [\n",
    "        f\"{date_str} {(start_time.hour + (i * 5) // 60) % 24:02d}:{((start_time.minute + i * 5) % 60):02d}\"\n",
    "        for i in range(gt_6h.shape[0])\n",
    "    ]\n",
    "\n",
    "    print(f\"  Time window: {time_labels_6h[0]} -> {time_labels_6h[-1]}\")\n",
    "    print(f\"  Shape: {gt_6h.shape}\")\n",
    "\n",
    "    output_path = (\n",
    "        OUTPUT_DIR\n",
    "        / f\"{EXPERIMENT_NAME}_{DATASET_NAME.lower()}_6h_rush_hour_comparison.gif\"\n",
    "    )\n",
    "    animate_traffic_heatmap(\n",
    "        values=gt_6h[:, :, 0],  # Take first feature (speed)\n",
    "        locations=locations,\n",
    "        output_path=output_path,\n",
    "        fps=ANIMATION_FPS,\n",
    "        duration_seconds=gt_6h.shape[0] / ANIMATION_FPS,\n",
    "        timestamps=time_labels_6h,\n",
    "        figsize=(18, 8),\n",
    "        cmap=\"RdYlGn_r\",\n",
    "        values_comparison=pred_6h[:, :, 0],\n",
    "        title_left=\"Ground Truth\",\n",
    "        title_right=\"Model Prediction\",\n",
    "        cvd_friendly=CVD_FRIENDLY,\n",
    "        basemap_source=BASEMAP_SOURCE,\n",
    "    )\n",
    "\n",
    "    # Display the GIF\n",
    "    display(Image(filename=str(output_path)))\n",
    "\n",
    "    print(f\"\\nâœ“ Completed visualizations for {DATASET_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Generated 3 visualizations for each dataset:\n",
    "1. **Node Degree Comparison** (PNG): Shows which sensors have the most connections\n",
    "2. **Geographic Nodes Animation** (GIF): Shows graph adjacency for selected sensors\n",
    "3. **6-Hour Rush Hour** (GIF): Compares ground truth vs model predictions over time\n",
    "\n",
    "All outputs saved to `outputs/visualizations/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
